{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafio #9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instalação de libs requeridas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libs de apoio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, display\n",
    "import os , random , json , requests\n",
    "import types\n",
    "import pandas as pd\n",
    "\n",
    "# Libs para criação de modelo DeepLearning\n",
    "# ATENÇÃO - Não utilizar o Keras interno do Tensorflow por incompatibilidade com o WML\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import InputLayer\n",
    "from keras.preprocessing import image as Kimage\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from imutils import paths\n",
    "\n",
    "# Libs para comunicação APIs Watson IBM\n",
    "from ibm_botocore.client import Config\n",
    "import ibm_boto3\n",
    "from watson_machine_learning_client import WatsonMachineLearningAPIClient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download do Dataset(imagens) da competição"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O dataset102.zip https://www.dropbox.com/s/trcr1k2dfmk8b44/DatasetBHTC.zip?dl=0\n",
    "\n",
    "!unzip -o ./dataset102.zip\n",
    "!mkdir DATASET\n",
    "!mv CLEAN DIRTY DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definição do Modelo - Não alterar o input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16, (3,3), input_shape=(96,96,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(16, (3,3), padding='same', activation='relu'))\n",
    "model.add(Conv2D(32, (3,3), padding='same', activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load das imagens, já com pre-processing, para utilizar no Train do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = sorted(list(paths.list_images('DATASET/')))\n",
    "\n",
    "random.seed(1)\n",
    "random.shuffle(imagePaths)\n",
    "\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "for imagePath in imagePaths:\n",
    "    image = Kimage.load_img(imagePath,target_size=(96,96))\n",
    "    image = img_to_array(image)\n",
    "    data.append(image)\n",
    "    label = imagePath.split(os.path.sep)[-2]\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split do dataset em Train e Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['CLEAN', 'DIRTY']\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "data = np.array(data, dtype=\"float\") / 255.0\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, test_size=0.2, random_state=1)\n",
    "\n",
    "print(\"shape de X de treino :\",trainX.shape)\n",
    "print(\"shape de Y de treino :\",trainY.shape)\n",
    "print(\"shape de X de teste :\",testX.shape)\n",
    "print(\"shape de Y de teste :\",testY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Treinamento do modelo - utilizando DataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aug = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.15,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.15,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "model.fit_generator(\n",
    "    aug.flow(trainX, trainY, batch_size=16),\n",
    "    validation_data=(testX, testY),\n",
    "    steps_per_epoch=len(trainX) // 16,\n",
    "    epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gráficos para avaliação do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H=model.history\n",
    "plt.rcParams['figure.figsize'] = 16, 8\n",
    "plt.figure()\n",
    "N = H.epoch[-1]+1\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save do modelo como model.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_WSTUDIO.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload do modelo no IBM Cloud Object Storage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload do modelo no IBM Watson Machine Learning - para export de API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o modelo deve estar em formato .tar.gz para subir no WML\n",
    "!tar -zcvf model_WSTUDIO.tar.gz model_WSTUDIO.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Credenciais do Watson Machine Learning\n",
    "wml_credentials  = {\n",
    "  \"apikey\": \"XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\",\n",
    "  \"iam_apikey_description\": \"Auto-generated for key XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\",\n",
    "  \"iam_apikey_name\": \"wdp-writer\",\n",
    "  \"iam_role_crn\": \"crn:v1:bluemix:public:iam::::serviceRole:Writer\",\n",
    "  \"iam_serviceid_crn\": \"crn:v1:bluemix:public:iam-identity::a/XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX::serviceid:ServiceId-XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\",\n",
    "  \"instance_id\": \"XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX\",\n",
    "  \"url\": \"https://us-south.ml.cloud.ibm.com\"\n",
    "}\n",
    "client = WatsonMachineLearningAPIClient( wml_credentials )\n",
    "\n",
    "# Definição de metadados do modelo (versao de python, framework, libs e etc)\n",
    "sample_saved_model_filename = 'model_WSTUDIO.tar.gz'\n",
    "metadata = {\n",
    "    client.repository.ModelMetaNames.NAME              : 'MY_FIRST_SUBMIT',\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_NAME    : 'tensorflow',\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_VERSION : '1.11',\n",
    "    client.repository.ModelMetaNames.RUNTIME_NAME      : 'python',\n",
    "    client.repository.ModelMetaNames.RUNTIME_VERSION   : '3.6',\n",
    "    client.repository.ModelMetaNames.FRAMEWORK_LIBRARIES :  [{\"name\": \"keras\", \"version\": \"2.2.4\"}]\n",
    "}\n",
    "\n",
    "\n",
    "# Conexão com o WML\n",
    "model_details = client.repository.store_model( sample_saved_model_filename, meta_props=metadata, training_data=None )\n",
    "\n",
    "# Deploy do modelo\n",
    "model_id = model_details[\"metadata\"][\"guid\"]\n",
    "model_deployment_details = client.deployments.create( artifact_uid=model_id, name=\"MY FIRST SUBMIT D9 Behind The Code\" )\n",
    "\n",
    "# Retrieve da URL da API para consumo da mesma\n",
    "model_endpoint_url = client.deployments.get_scoring_url( model_deployment_details )\n",
    "print(\"A URL de chamada da sua API é : \",model_endpoint_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chamada da API para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download de imagem teste\n",
    "!wget -O teste2.jpg https://www.dropbox.com/s/73fofwe566749sl/teste123.jpg?dl=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montagem da estrutura de JSON para chamada da API do WML\n",
    "ai_parms = { \"wml_credentials\" : wml_credentials, \"model_endpoint_url\" : model_endpoint_url }\n",
    "\n",
    "# Load da imagem de teste e pre-processing da mesma - para entrada na rede neural convolucional\n",
    "image = Kimage.load_img(\"teste2.jpg\")\n",
    "plt.imshow(image)\n",
    "image = image.resize(size=(96,96))\n",
    "image = img_to_array(image)\n",
    "image = np.array(image, dtype=\"float\") / 255.0\n",
    "image = np.expand_dims(image,axis=0)\n",
    "image = image.tolist()\n",
    "\n",
    "# Chamada da função SCORE no modelo (inference)\n",
    "model_payload = { \"values\" : image }\n",
    "model_result = client.deployments.score( ai_parms[\"model_endpoint_url\"], model_payload )\n",
    "print(model_result)\n",
    "\n",
    "print(\"\\nImagem Classificada como : \", classes[model_result['values'][0][1][0]])\n",
    "\n",
    "print(\"\\nProbabilidades : \\n\\t\",\n",
    "      classes[model_result['values'][0][1][0]],\" : %.2f\" %(model_result['values'][0][0][0]*100),\"%\\n\\t\",\n",
    "     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BOA SORTE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
